---
title: "Exam-1"
output: pdf_document
date: "2024-10-02"
---

1. (6 points, 1 point each). True or False. Answer True or False for each part below. You do not need to explain your rationale for credit.

a. The four stages of the data cleaning pipeline are as follows: 1. schema alignment, principal components
analysis, entity resolution, and canonicalization.
False

b. One application of entity resolution is predicting if two finger prints are matches (or not matches).
True

c. One challenge of the data cleaning pipeline is scaling to large databases.
False

d. Suppose a data set has a total of R records. In the blocking stage, there are R total record comparisons that can be made.
False?

e. The output of entity resolution can tells us if record pairs are matches or non-matches. It does not tells us what record is the most representative entity (person) in the data set.
True

f. The goal of schema alignment is to remove duplicate entities from large databases.
False

2. 6 points (1 point each).
a. Compute the Jaccard similarity for each pair of the following three sets:
S1 = {1, 2, 3, 4}, S2 = {2, 3, 5, 7}, and S3 = {2, 4, 6}
Do this using R and do not compute this by hand.
```{r}
library(textreuse)
library(tokenizers)
S1 <- c(1, 2, 3, 4)
S2 <- c(2, 3, 5, 7)
S3 <- c(2, 4, 6)
```

```{r}
jaccard_similarity(S1,S2)
jaccard_similarity(S1,S3)
jaccard_similarity(S2,S3)
```


b. Consider two sentences:
“The plane was ready for touch down” and “The quarterback scored a touchdown”
Find the set of 9-shingles for each sentence, where you should ignore blanks (or spaces). Do this using R and do not compute this by hand.

```{r}
token_1 <- tokenize_character_shingles("Theplanewasreadyfortouchdown", n=9)
token_2 <- tokenize_character_shingles("Thequarterbackscoredatouchdown", n=9)

jaccard_similarity(unlist(token_1),unlist(token_2))
```
c. Explain why we do not store data in the form of a characteristic matrix (for practical purposes).
It takes up too much space - signature matrix is more efficient as it only take the hashed values.

d. Explain what the minhash function does to the characterisic matrix. Hint: Think about the rows versus the columns.

We use minhash function to create signature matrix. During minhash process, we first permuate the rows of characteristic matrix m times, iterate over each column of permuted matrix, and populate the signature matrix row-wise, with the row index from the first 1 value found in the column. 

Citation: Probabilistic Blocking Part II Slide 14

e. Explain (in words) the connection between minhashing and the Jaccard similarity of the sets that are minhashed.

The random permutations of the characteristic matrix, a step of minhashing process, equals to the Jaccard similarity. ? 

Citation: Probabilistic Blocking Part II Slide 16

f. Consider the following permuted matrix, where the columns are records and the rows are shingles:
```{r}
s1 <- c(0, 0, 1, 0)
s2 <- c(0, 1, 1, 1)
s3 <- c(1, 0, 0, 0)
s4 <- c(1, 1, 0, 1)
permuted_matrix <- rbind(s1, s2 , s3, s4)
permuted_matrix
```
Find the first row of the signature matrix S. You may answer this either by hand or using R.
{3,2,1,1}?


3. (10 points) Consider the cora data set that we considered in class and in homework
```{r}
# packages
if (!require("pacman")) {
install.packages("pacman")
library(pacman)
}
## Loading required package: pacman
p_load(RecordLinkage, blink, knitr, textreuse, tokenizers, devtools, cora,
ggplot2, dplyr, numbers)
data(cora) # load the cora data set
data(cora_gold)
data(cora_gold_update)
```

Observe that cora_gold contains record pairs that refer to the same person (entity). The data set cora_gold_update contains two columns, cora_id and unique_id. The first column, cora_id, refers to the row number in the cora data set. The second column, unique_id, refers to a unique identifier for each record. For instance, the first six records correspond to the unique identifer 1.

Unfortunately, upon further inspection, there are errors in cora_gold_update.

a. (2 points) Validate (empirically) that there are errors in cora_gold_update. Hint: Check to see which id pairs in cora_gold do not map to the same unique id in cora_gold_update.
```{r}
#If the id paris do not map to the same unique id 
#then they are not the same entity, hence error
#merge cora_gold_update with cora_gold on cora_id to get unique id for id1
merged_cora_gold <- merge(cora_gold, cora_gold_update, by.x = "id1", 
                          by.y = "cora_id", all.x = TRUE)
#merge again to get unique id for id2
merged_cora_gold <- merge(merged_cora_gold, cora_gold_update, by.x = "id2", 
                          by.y = "cora_id", all.x = TRUE, suffixes = c("_id1", "_id2"))

errors <- merged_cora_gold[merged_cora_gold$unique_id_id1 != merged_cora_gold$unique_id_id2, ]
errors
```

b. (2 points) Calculate how many inconsistencies exist between cora_gold and cora_gold_update based upon part (a).
```{r}
# Count the number of inconsistencies
inconsistencies <- nrow(errors)
inconsistencies
```
There are 21856 inconsistencies. 

c. (6 points)
Using cora_gold, write code such that cora_gold_update that maintains the same mapping.
```{r}
cora_gold_update_2 <- cora_gold_update

# Initialize a variable to track if any changes were made in an iteration
changed <- TRUE

# Repeat the process until no more inconsistencies are found
while (changed) {
  # Merge cora_gold with cora_gold_update_2 to get current unique ids for id1 and id2
  merged_cora_gold_2 <- merge(cora_gold, cora_gold_update_2, by.x = "id1", 
                              by.y = "cora_id", all.x = TRUE)
  merged_cora_gold_2 <- merge(merged_cora_gold_2, cora_gold_update_2, by.x = "id2", 
                              by.y = "cora_id", all.x = TRUE, suffixes = c("_id1", "_id2"))
  
  # Identify inconsistencies where unique_id of id1 and id2 are different
  errors <- merged_cora_gold_2[merged_cora_gold_2$unique_id_id1 != merged_cora_gold_2$unique_id_id2, ]
  
  # If no errors are found, set changed to FALSE to exit the loop
  if (nrow(errors) == 0) {
    changed <- FALSE
  } else {
    # For each error, update the unique_id to the minimum of the two for both id1 and id2
    for (i in 1:nrow(errors)) {
      id1 <- errors$id1[i]
      id2 <- errors$id2[i]
      correct_unique_id <- min(errors$unique_id_id1[i], errors$unique_id_id2[i])
      
      # Update the unique_id for all records with cora_id equal to id1 or id2
      cora_gold_update_2$unique_id[
        cora_gold_update_2$cora_id %in% c(id1, id2)
      ] <- correct_unique_id
    }
  }
}
```

(i) Validate that all matches have the same unique id. Provide a Boolean result.
```{r}
#If the id paris do not map to the same unique id 
#then they are not the same entity, hence error
#merge cora_gold_update with cora_gold on cora_id to get unique id for id1
merged_cora_gold_2 <- merge(cora_gold, cora_gold_update_2, by.x = "id1", 
                          by.y = "cora_id", all.x = TRUE)
#merge again to get unique id for id2
merged_cora_gold_2 <- merge(merged_cora_gold_2, cora_gold_update_2, by.x = "id2", 
                          by.y = "cora_id", all.x = TRUE, suffixes = c("_id1", "_id2"))

merged_cora_gold_2$unique_id_id1 == merged_cora_gold_2$unique_id_id2
```

(ii) Validate that the number of inconsistencies is now 0.
```{r}
errors_2 <- merged_cora_gold_2[merged_cora_gold_2$unique_id_id1 != merged_cora_gold_2$unique_id_id2, ]
nrow(errors_2)
```

